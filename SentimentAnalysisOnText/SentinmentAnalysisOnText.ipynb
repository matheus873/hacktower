{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SentinmentAnalysisOnText.ipynb","provenance":[],"authorship_tag":"ABX9TyO71bLl3o7u+ZjCcKjX4zQW"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"LZRcTZo8Otwn","executionInfo":{"status":"ok","timestamp":1602485516128,"user_tz":-330,"elapsed":1699,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}}},"source":["import pandas as pd\n","import numpy as np\n","data = pd.read_csv('text_emotion.csv')"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OamsBx9RO_9g"},"source":["Considering only happiness and sadness \n"," - if out want you can remove drops"]},{"cell_type":"code","metadata":{"id":"gCCV1NQ1O2Lz","executionInfo":{"status":"ok","timestamp":1602485516130,"user_tz":-330,"elapsed":1690,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}}},"source":["data = data.drop('author', axis=1)\n","# Dropping rows with other emotion labels\n","data = data.drop(data[data.sentiment == 'anger'].index)\n","data = data.drop(data[data.sentiment == 'boredom'].index)\n","data = data.drop(data[data.sentiment == 'enthusiasm'].index)\n","data = data.drop(data[data.sentiment == 'empty'].index)\n","data = data.drop(data[data.sentiment == 'fun'].index)\n","data = data.drop(data[data.sentiment == 'relief'].index)\n","data = data.drop(data[data.sentiment == 'surprise'].index)\n","data = data.drop(data[data.sentiment == 'love'].index)\n","data = data.drop(data[data.sentiment == 'hate'].index)\n","data = data.drop(data[data.sentiment == 'neutral'].index)\n","data = data.drop(data[data.sentiment == 'worry'].index)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"0KPqSsinPkKt","executionInfo":{"status":"ok","timestamp":1602485516547,"user_tz":-330,"elapsed":2099,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}},"outputId":"134b59fb-ec66-4589-a9d8-7fea7ff9a019","colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","#Making all letters lowercase\n","data['content'] = data['content'].apply(lambda x: \" \".join(x.lower() for x in x.split()))\n","#Removing Punctuation, Symbols\n","data['content'] = data['content'].str.replace('[^\\w\\s]',' ')\n","#Removing Stop Words using NLTK\n","from nltk.corpus import stopwords\n","stop = stopwords.words('english')\n","data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fpsxrGUNPpHC","executionInfo":{"status":"ok","timestamp":1602485517389,"user_tz":-330,"elapsed":2930,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}}},"source":["#Lemmatisation\n","from textblob import Word\n","data['content'] = data['content'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n","#Correcting Letter Repetitions\n","import re\n","def de_repeat(text):\n","    pattern = re.compile(r\"(.)\\1{2,}\")\n","    return pattern.sub(r\"\\1\\1\", text)\n","\n","data['content'] = data['content'].apply(lambda x: \" \".join(de_repeat(x) for x in x.split()))"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"78Fotc14PtUA","executionInfo":{"status":"ok","timestamp":1602485531574,"user_tz":-330,"elapsed":17106,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}}},"source":["# Code to find the top 10,000 rarest words appearing in the data\n","freq = pd.Series(' '.join(data['content']).split()).value_counts()[-10000:]\n","# Removing all those rarely appearing words from the data\n","freq = list(freq.index)\n","data['content'] = data['content'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"0nsxcic3PycZ","executionInfo":{"status":"ok","timestamp":1602485531576,"user_tz":-330,"elapsed":17101,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}}},"source":["#Encoding output labels 'sadness' as '1' & 'happiness' as '0'\n","from sklearn import preprocessing\n","lbl_enc = preprocessing.LabelEncoder()\n","y = lbl_enc.fit_transform(data.sentiment.values)\n","# Splitting into training and testing data in 90:10 ratio\n","from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(data.content.values, y, stratify=y, random_state=42, test_size=0.1, shuffle=True)\n"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"L-V_yxbQP1aY","executionInfo":{"status":"ok","timestamp":1602485531577,"user_tz":-330,"elapsed":17097,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}}},"source":["# Extracting TF-IDF parameters\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","tfidf = TfidfVectorizer(max_features=1000, analyzer='word',ngram_range=(1,3))\n","X_train_tfidf = tfidf.fit_transform(X_train)\n","X_val_tfidf = tfidf.fit_transform(X_val)\n"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"8mnieJDeP4EI","executionInfo":{"status":"ok","timestamp":1602485531577,"user_tz":-330,"elapsed":17092,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}}},"source":["# Extracting Count Vectors Parameters\n","from sklearn.feature_extraction.text import CountVectorizer\n","count_vect = CountVectorizer(analyzer='word')\n","count_vect.fit(data['content'])\n","X_train_count =  count_vect.transform(X_train)\n","X_val_count =  count_vect.transform(X_val)\n"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"vH3PmvvDRTts","executionInfo":{"status":"ok","timestamp":1602485531578,"user_tz":-330,"elapsed":17089,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}},"outputId":"34419213-a046-49a7-add9-b0107512cf2a","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from sklearn.metrics import accuracy_score\n","# Model : Linear SVM\n","from sklearn.linear_model import SGDClassifier\n","lsvm = SGDClassifier(alpha=0.001, random_state=5, max_iter=15, tol=None)\n","lsvm.fit(X_train_count, y_train)\n","y_pred = lsvm.predict(X_val_count)\n","print('lsvm using count vectors accuracy %s' % accuracy_score(y_pred, y_val))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["lsvm using count vectors accuracy 0.7842003853564548\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ECIeOYGHS1zo","executionInfo":{"status":"ok","timestamp":1602485531578,"user_tz":-330,"elapsed":17082,"user":{"displayName":"Joe Ral","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhNO1q6Fa3CLBYXhluVYogAqwHSgmXrJtuK1fv=s64","userId":"14007218767504286621"}},"outputId":"d3b284c8-c366-4a15-bd91-ba5b6fd2a1c3","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["\n","testSet = pd.DataFrame(['I am very happy today! The atmosphere looks cheerful',\n","'Things are looking great. It was such a good day',\n","'Success is right around the corner. Lets celebrate this victory',\n","'Everything is more beautiful when you experience them with a smile!',\n","'Now this is my worst, okay? But I am gonna get better.',\n","'I am tired, boss. Tired of being on the road, lonely as a sparrow in the rain. I am tired of all the pain I feel',\n","'This is quite depressing. I am filled with sorrow',\n","'Congrats on your promotion!'])\n","# Doing preprocessing as done before\n","testSet[0] = testSet[0].str.replace('[^\\w\\s]',' ')\n","from nltk.corpus import stopwords\n","stop = stopwords.words('english')\n","testSet[0] = testSet[0].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n","from textblob import Word\n","testSet[0] = testSet[0].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n","# Extracting Count Vectors feature TestSet\n","countVectorsFromTestSample = count_vect.transform(testSet[0])\n","#Predicting the emotion of the TestSet using our already trained linear SVM\n","predictionsFromTestSample = lsvm.predict(countVectorsFromTestSample)\n","print(predictionsFromTestSample)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["[0 0 0 0 1 1 1 0]\n"],"name":"stdout"}]}]}